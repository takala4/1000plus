---
documentclass: bxjsarticle
title: 20210103
yesterday: 20210102
tomorrow: 20210104
days: 373
author: Takala
header-includes:
  - \usepackage[margin=1in]{geometry}
  - \usepackage[ISO]{diffcoeff}
  - \usepackage{pxfonts}
---



昨日書いた読書メーターのデータをエクスポートするスクレイピングコードを酔っ払いながら書いた．



```python


# BMスクレイピング用
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
import chromedriver_binary 

from bs4 import BeautifulSoup as bs4


import json
import time


def get_ASIN(BM_Number):
    URL = 'https://bookmeter.com/books/%s'%BM_Number
    driver.get(URL)
    
    amazon_link = driver.find_element_by_class_name('image__cover').get_attribute("href")
    asin = amazon_link.split('product/')[1].split('/')[0]

    return asin

options = Options()
# options.add_argument('--headless')

driver = webdriver.Chrome(options=options)

BM_user_id = 'XXXXX'


URL = 'https://bookmeter.com/users/%s/reviews'%BM_user_id
driver.get(URL)

time.sleep(5)

# 下までスクロール
for i in range(30):
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(0.8)
    
# soupに流し込み
soup = bs4(driver.page_source)
driver.close()

book_list = soup.find_all(class_="partials_resources frame")


books = {}
for book in book_list:    
    Title = book.find_all(class_="frame__content__book__detail__item")[0].get_text()
    Author = book.find_all(class_="frame__content__book__detail__item frame__content__book__detail__item--author")[0].get_text()
    BM_Number = book.find_all(class_ = "frame__content__frame__side")[0].get('href').split('/')[2]
    Date =  book.find_all(class_ = "frame__details__date frame__details__date--link")[0].get_text()

    
    Comment = []
    for c in book.find_all(class_="frame__content__text"):
        Comment = Comment + [c.get_text()]
        
        
    books[BM_Number] = {}
    books[BM_Number]['Title'] = Title
    books[BM_Number]['Author'] = Author
    books[BM_Number]['BM_Number'] = BM_Number
    books[BM_Number]['Comment'] = Comment
    books[BM_Number]['Date'] = Date



driver = webdriver.Chrome(options=options)
for key in list(books.keys())[:74:]:
    asin = get_ASIN(key)
    books[key]['ASIN'] = asin
    time.sleep(3)
    
driver.close()


path = 'BM_log.json'
f = open('BM_log.json', 'w', encoding='utf-8-sig')
json.dump(books, f, indent=2)
f.close()

```


こんな感じ．ところどころ`time.sleep()`いれないとBANされる．実際テスト中にされた．


一回一覧から全書籍データを取得して，そのあと個別ページに飛んでASINを取得している．


今回はじめて気づいたが，書籍のkindle版には「ISBNを変換して作られれるASIN」とはまた別のkindle用ASINが付与されているよう．．．



管理がめんどくさいなー
